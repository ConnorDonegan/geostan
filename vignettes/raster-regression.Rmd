---
title: "Raster regression"
date: April 27, 2023
author: Connor Donegan
output: 
  rmarkdown::html_vignette:
    toc: false
header-includes:
   - \usepackage{amsmath}
vignette: >
  %\VignetteIndexEntry{Raster regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: raster.bib
link-citations: yes
---

This vignette provides a tutorial for fitting spatial regression models to raster data using **geostan**. The term "raster" is used here to refer to any regularly spaced set of observations such that the data can be represented spatially by a rectangular grid of observations, such as remotely sensed imagery. While **geostan** can be used for spatial regression with large raster data layers, the functionality of these models will often be limited to the estimation of regression coefficients and spatial autocorrelation parameters. Thus far, no attempt has been made to test the limits of these models. Limited experience finds that spatial autoregressive models can be fit to raster layers with over a million observations using only a laptop computer and a few dozen minutes. 

Start by loading some necessary R packages.

```{r setup, message = FALSE, warning = FALSE}
library(geostan)
library(sf)
```

We will start by creating a small raster data layer for the purpose of illustration.

```{r}
row <- 40
col <- 30
c(N <- row * col)
sfc = st_sfc(st_polygon(list(rbind(c(0,0), c(col,0), c(col,row), c(0,0)))))
grid <- st_make_grid(sfc, cellsize = 1, square = TRUE)
grid <- st_as_sf(grid)
W <- shape2mat(grid, style = "W", queen = FALSE)
grid$z <- sim_sar(w = W, rho = 0.9)
grid$y <- -0.5 * grid$z + sim_sar(w = W, rho = .9, sigma = .3)
plot(grid[,'z'])
moran_plot(grid$z, W)
moran_plot(grid$y, W)
```

The following R code would fit a spatial autoregressive model to these data:

```{r eval = FALSE}
fit <- stan_sar(y ~ z, data = grid, C = W)
```
or for the conditional autoregressive (CAR) model:

```{r eval = FALSE}
C <- shape2mat(grid, style = "B", queen = FALSE)
car_list <- prep_car_data(C, "WCAR")
fit <- stan_car(y ~ z, data = grid, car_parts = car_list)
```

The `stan_sar` function will take the spatial weights matrix `W` and pass it through a function called `prep_sar_data`. For the CAR model, the user is required to use the `prep_car_data` function explicitly in order to select a model specification. The `prep_*_data` functions calculate the eigenvalues of the spatial weights matrix, and these are required for computational reasons [@donegan_2022]. The standard computations used to obtain the eigenvalues are prohibitively expensive in terms of computation time.

The `prep_sar_data2` and `prep_car_data2` functions are designed for raster layers. The eigenvalues are produced very quickly using Equation 5 from @griffith_2000. The methods have certain restrictions. First, this is only applicable to raster layers---regularly spaced, rectangular grids of observations. Second, to define which observations are adjacent to one another, the "rook" criteria is used (spatially, only observations that share an edge are neighbors to one another). Third, the spatial adjacency matrix will be row-standardized. This is standard (required) for SAR models, and corresponds to the "WCAR" specification of the CAR model [see @donegan_2022].

The following code will fit a SAR model to our `grid` data, and can also handle much larger raster layers:

```{r}
sar_list <- prep_sar_data2(row = row, col = col)
fit <- stan_sar(
                y ~ z, 
                data = grid,
		sar_parts = sar_list,
		iter = 400,
		chains = 4,
		slim = TRUE #,
		# cores = 4, # for mulit-core processing
		)
print(fit)		
```
There are few things to note about these results and the model call.

 1. **slim = TRUE**: A typical **geostan** model will return Markov chain Monte Carlo (MCMC) samples from all model parameters as well as the fitted values and pointwise log-likelihoods (for calculating the Widely Applicable Information Criteria, WAIC). Collecting these vectors of parameters becomes computationally demanding for large data sets. The `slim = TRUE` argument prevents collection of the fitted values and log-likelihoods, speeding up the models considerably, but also limiting the uses to which they may be put.

 2. **iter = 400, chains = 4**: Small numbers of MCMC samples can be sufficient to obtain reasonable MCMC samples. In this case, the effective sample sizes `n_eff` are sufficiently large for most purposes and the standard errors of the estimates `se_mean` are sufficiently small. More importantly, there are no signs that the four MCMC chains failed to converge on a single distribution---despite collecting only 200 warmup samples per chain. For large data sets, one can expect to require a modestly larger number of MCMC samples than were required for this example.

 3. **centering and scaling**: the synthetic data `grid$z` is nearly standard normal, and this contributes to the quick sampling speed. Stan models sample most quickly with standard normal variates. For large data sets, it can be extremely helpful to scale each variable using the `base::scale` function before passing the data to a model fitting function like `stan_car`.

 4. **SAR vs. CAR**: So far, neither seems to outpace the other in terms of computational efficiency with raster layers.

## References
